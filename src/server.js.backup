const express = require('express');
const cors = require('cors');
const helmet = require('helmet');
const morgan = require('morgan');
require('dotenv').config();

const { OllamaOrchestrator } = require('./services/orchestrator');
const { EmbeddingClassifier } = require('./services/embeddingClassifier');
const { RequestLogger } = require('./middleware/requestLogger');
const { ErrorHandler } = require('./middleware/errorHandler');
const { SessionManager } = require('./services/sessionManager');
const { SmartContextManager } = require('./services/smartContextManager');
const { AgenticWorkflowExecutor } = require('./services/agenticWorkflowExecutor');
const { AICodeAnalyzer } = require('./services/aiCodeAnalyzer');
const { EnhancedContextManager } = require('./services/enhancedContextManager');
const IntentRecognizer = require('./services/intentRecognizer');
const ApproachMapper = require('./services/approachMapper');

// Helper function to generate tool plan summary
function generateToolPlanSummary(toolPlan) {
  const { description, tools } = toolPlan;
  return `${description} - ${tools.length} tools needed`;
}

const app = express();
const PORT = process.env.PORT || 3003;

// Initialize services
const orchestrator = new OllamaOrchestrator();
const embeddingClassifier = new EmbeddingClassifier();
const sessionManager = new SessionManager();
const contextManager = new SmartContextManager();
const agenticExecutor = new AgenticWorkflowExecutor();
const aiCodeAnalyzer = new AICodeAnalyzer();
const enhancedContextManager = new EnhancedContextManager();
const intentRecognizer = new IntentRecognizer();
const approachMapper = new ApproachMapper();

// Middleware
app.use(helmet());
app.use(cors());
app.use(express.json({ limit: '50mb' }));
app.use(express.urlencoded({ extended: true, limit: '50mb' }));

// Logging middleware
if (process.env.LOG_REQUESTS === 'true') {
  app.use(morgan('combined'));
  app.use(RequestLogger.middleware);
}

// Health check endpoint
app.get('/health', (req, res) => {
  res.json({
    status: 'healthy',
    service: 'ollama-geek',
    timestamp: new Date().toISOString()
  });
});

// Session management endpoint (for debugging)
app.get('/api/sessions', (req, res) => {
  res.json(sessionManager.getStats());
});

// Tool execution endpoints removed - this is now a planning-only API

// AI Code Analysis endpoint
app.post('/api/ai/analyze', async (req, res, next) => {
  try {
    const { filePath, options } = req.body;

    if (!filePath) {
      return res.status(400).json({ error: 'File path is required' });
    }

    const analysis = await aiCodeAnalyzer.analyzeCode(filePath, options);
    res.json(analysis);
  } catch (error) {
    next(error);
  }
});

// AI Code Refactoring endpoint
app.post('/api/ai/refactor', async (req, res, next) => {
  try {
    const { filePath, refactoringType, options } = req.body;

    if (!filePath || !refactoringType) {
      return res.status(400).json({ error: 'File path and refactoring type are required' });
    }

    const refactoring = await aiCodeAnalyzer.refactorCode(filePath, refactoringType, options);
    res.json(refactoring);
  } catch (error) {
    next(error);
  }
});

// AI Test Generation endpoint
app.post('/api/ai/tests', async (req, res, next) => {
  try {
    const { filePath, testFramework, options } = req.body;

    if (!filePath) {
      return res.status(400).json({ error: 'File path is required' });
    }

    const tests = await aiCodeAnalyzer.generateTests(filePath, testFramework, options);
    res.json(tests);
  } catch (error) {
    next(error);
  }
});

// AI Debugging endpoint
app.post('/api/ai/debug', async (req, res, next) => {
  try {
    const { filePath, errorContext, options } = req.body;

    if (!filePath) {
      return res.status(400).json({ error: 'File path is required' });
    }

    const debugging = await aiCodeAnalyzer.debugCode(filePath, errorContext, options);
    res.json(debugging);
  } catch (error) {
    next(error);
  }
});

// AI Code Review endpoint
app.post('/api/ai/review', async (req, res, next) => {
  try {
    const { filePath, reviewType, options } = req.body;

    if (!filePath) {
      return res.status(400).json({ error: 'File path is required' });
    }

    const review = await aiCodeAnalyzer.reviewCode(filePath, reviewType, options);
    res.json(review);
  } catch (error) {
    next(error);
  }
});

// AI Documentation Generation endpoint
app.post('/api/ai/documentation', async (req, res, next) => {
  try {
    const { filePath, docType, options } = req.body;

    if (!filePath) {
      return res.status(400).json({ error: 'File path is required' });
    }

    const documentation = await aiCodeAnalyzer.generateDocumentation(filePath, docType, options);
    res.json(documentation);
  } catch (error) {
    next(error);
  }
});

// AI Code Optimization endpoint
app.post('/api/ai/optimize', async (req, res, next) => {
  try {
    const { filePath, optimizationType, options } = req.body;

    if (!filePath) {
      return res.status(400).json({ error: 'File path is required' });
    }

    const optimization = await aiCodeAnalyzer.optimizeCode(filePath, optimizationType, options);
    res.json(optimization);
  } catch (error) {
    next(error);
  }
});

// AI Cache management endpoint
app.get('/api/ai/cache', (req, res) => {
  res.json(aiCodeAnalyzer.getCacheStats());
});

app.delete('/api/ai/cache', (req, res) => {
  const result = aiCodeAnalyzer.clearCache();
  res.json(result);
});

// Old tools endpoint removed - replaced with planning-only version below

// Tool execution history removed - this is now a planning-only API

  // Ollama API endpoints - these maintain complete compatibility
  app.post('/api/show', async (req, res, next) => {
  try {
    console.log('ðŸ” /api/show endpoint called');
    console.log('ðŸ“‹ Request body:', JSON.stringify(req.body, null, 2));

    // Get model info from Ollama
    const axios = require('axios');
    const ollamaResponse = await axios.post('http://localhost:11434/api/show', req.body);

    // Get available tools from our services
    const availableTools = [
      {
        name: "create_file",
        description: "Create new files with specified content",
        parameters: {
          path: "string - File path to create",
          content: "string - File content",
          language: "string - Programming language (optional)"
        }
      },
      {
        name: "create_directory",
        description: "Create new directories",
        parameters: {
          path: "string - Directory path to create"
        }
      },
      {
        name: "edit_file",
        description: "Modify existing files",
        parameters: {
          path: "string - File path to edit",
          content: "string - New file content"
        }
      },
      {
        name: "delete_file",
        description: "Remove files",
        parameters: {
          path: "string - File path to delete"
        }
      },
      {
        name: "run_terminal",
        description: "Execute terminal commands",
        parameters: {
          command: "string - Command to execute",
          cwd: "string - Working directory (optional)"
        }
      },
      {
        name: "git_operation",
        description: "Perform git operations",
        parameters: {
          operation: "string - Git command (init, add, commit, etc.)",
          path: "string - Repository path (optional)"
        }
      },
      {
        name: "search_files",
        description: "Search file content",
        parameters: {
          query: "string - Search query",
          path: "string - Directory to search (optional)"
        }
      }
    ];

    // Add OllamaGeek enhancement info with tool capabilities
    // Note: Continue expects tools in Ollama's native format
    const enhancedResponse = {
      ...ollamaResponse.data,
      ollamageek_enhanced: true,
      orchestration: 'OllamaGeek enhanced response',
      // Expose tools in Ollama's expected format
      tools: availableTools.map(tool => ({
        type: "function",
        function: {
          name: tool.name,
          description: tool.description,
          parameters: {
            type: "object",
            properties: Object.fromEntries(
              Object.entries(tool.parameters).map(([key, value]) => [
                key,
                { type: "string", description: value }
              ])
            ),
            required: Object.keys(tool.parameters)
          }
        }
      })),
      // Add tool capabilities to the existing capabilities
      capabilities: {
        ...ollamaResponse.data.capabilities,
        tool_execution: true,
        file_operations: true,
        terminal_commands: true,
        git_operations: true,
        code_analysis: true,
        project_generation: true,
        function_calling: true,
        tool_use: true
      },
      // Add tools to modelfile so Continue can see them
      modelfile: (ollamaResponse.data.modelfile || '') + '\n\n# OllamaGeek Tools\n' + availableTools.map(tool =>
        `TOOL ${tool.name} "${tool.description}"`
      ).join('\n'),
      system_prompt: "You are OllamaGeek, an intelligent AI assistant with access to powerful tools for file operations, terminal commands, git operations, and code analysis. You can execute tools directly to help users with their coding tasks."
    };

    console.log(`ðŸ› ï¸ Exposed ${availableTools.length} tools to Continue`);
    res.json(enhancedResponse);
  } catch (error) {
    console.error('âŒ Error in /api/show:', error.message);
    res.status(500).json({ error: 'Failed to show model info' });
  }
});

app.post('/api/generate', async (req, res, next) => {
  try {
    const result = await orchestrator.handleGenerate(req.body);
    res.json(result);
  } catch (error) {
    next(error);
  }
});

app.post('/api/chat', async (req, res, next) => {
  try {
    // Session management: Create or get session ID
    const userAgent = req.get('User-Agent') || 'unknown';
    const sessionId = sessionManager.getSessionId(req.body, userAgent);
    const sessionHistory = sessionManager.getSessionHistory(sessionId);

    // Log session information
    console.log(`ðŸ†” Session: ${sessionId} | History: ${sessionHistory.length} messages | User-Agent: ${userAgent.substring(0, 50)}...`);

    // Use embedding-based classification for intelligent model selection
    const analysis = await embeddingClassifier.classifyRequest(req.body);
    const recommendedModel = analysis.recommendedModel;

    // Log the embedding classification decision
    console.log(`ðŸ§  Embedding Classification: "${req.body.model}" -> "${recommendedModel}"`);
    console.log(`ðŸ“Š Analysis: ${analysis.taskType} | ${analysis.complexity} | ${analysis.language} | ${analysis.reasoning}`);

    // Get smart context for the request (fast heuristics + AI when needed)
    const context = await contextManager.getSmartContext(req.body, analysis.taskType, analysis.complexity);
    if (context.files.length > 0 || context.gitStatus || context.reasoning) {
      console.log(`ðŸ“ Smart Context: ${contextManager.formatContext(context)}`);
    }

        // Analyze if tools are needed
    const content = req.body.prompt || (req.body.messages && req.body.messages.length > 0 ? req.body.messages[req.body.messages.length - 1].content : '');

    // Get tool plan from Ollama's intelligence
    console.log(`ðŸ§  Getting tool plan from Ollama...`);
    const toolPlan = await agenticExecutor.planTools(req.body, context);

    if (toolPlan && toolPlan.tools.length > 0) {
      // Add tool plan to context for Continue to use
      context.toolPlan = toolPlan;
      console.log(`ðŸŽ¯ Tool plan generated: ${toolPlan.tools.length} tools needed`);
      console.log(`ðŸ“‹ Plan description: ${toolPlan.description}`);
      console.log(`ðŸ”§ Tools: ${toolPlan.tools.map(t => t.tool).join(', ')}`);

      // Add tool plan to the user message so Continue knows what to do
      if (req.body.messages && req.body.messages.length > 0) {
        const lastMessage = req.body.messages[req.body.messages.length - 1];
        if (lastMessage.role === 'user') {
          lastMessage.content += `\n\n[TOOL PLAN: ${toolPlan.description}]\n\nContinue should execute these tools:\n${toolPlan.tools.map((t, i) => `${i + 1}. ${t.tool}: ${t.description}`).join('\n')}\n\nContext: ${toolPlan.context}`;
        }
      }
    } else {
      console.log(`âŒ No tool plan generated`);
    }

    // Check if planning is needed
    if (analysis.needsPlanning) {
      const planningSteps = analysis.planningSteps;
      console.log(`ðŸ“‹ Planning Required: ${planningSteps.join(' â†’ ')}`);
    }

        // Forward to Ollama with the intelligently selected model
    const axios = require('axios');

    // Debug: Log what we're sending to Ollama
    const ollamaRequest = {
      ...req.body,
      model: recommendedModel,
      stream: req.body.stream !== false // Default to true for Continue compatibility
    };

    // Add model information to the request for context
    ollamaRequest.ollamageek_context = {
      selectedModel: recommendedModel,
      toolPlanGenerated: context.toolPlan ? true : false,
      timestamp: new Date().toISOString()
    };

    // Clean the request to remove any potentially problematic fields
    const cleanRequest = {
      model: ollamaRequest.model,
      messages: ollamaRequest.messages,
      stream: ollamaRequest.stream
    };

    // Add options if they exist and are valid
    if (ollamaRequest.options && typeof ollamaRequest.options === 'object') {
      cleanRequest.options = ollamaRequest.options;
    }

    // Add any other valid Ollama parameters
    if (ollamaRequest.template) cleanRequest.template = ollamaRequest.template;
    if (ollamaRequest.context) cleanRequest.context = ollamaRequest.context;
    if (ollamaRequest.keep_alive) cleanRequest.keep_alive = ollamaRequest.keep_alive;

    console.log(`ðŸ“¤ Sending to Ollama:`, JSON.stringify(cleanRequest, null, 2));
    console.log(`ðŸ” Original request body:`, JSON.stringify(req.body, null, 2));
    console.log(`ðŸŽ¯ Recommended model:`, recommendedModel);
    console.log(`ðŸ§¹ Cleaned request:`, JSON.stringify(cleanRequest, null, 2));

        // Check if this is a tool execution request from Continue
    if (req.body.tools && req.body.tools.length > 0) {
      console.log(`ðŸ› ï¸ Continue sent tools: ${req.body.tools.map(t => t.function?.name || t.name).join(', ')}`);

      // For now, let's not modify the tools in the request to Ollama
      // as this might be causing the 400 error
      console.log(`ðŸ”„ Continue tool execution mode - passing through to Ollama without modification`);

      // We'll handle tool execution differently - by intercepting the response
      // and executing tools when Ollama requests them
    }

    // Check if streaming is requested
    const isStreaming = ollamaRequest.stream;

    if (isStreaming) {
      // Handle streaming response
      try {
        const ollamaResponse = await axios.post(`${process.env.OLLAMA_BASE_URL || 'http://localhost:11434'}/api/chat`, cleanRequest, {
          responseType: 'stream',
          headers: {
            'Content-Type': 'application/json'
          }
        });

        // Set streaming headers
        res.setHeader('Content-Type', 'application/x-ndjson');
        res.setHeader('Transfer-Encoding', 'chunked');

                // Intercept the stream to inject model information
        let firstChunk = true;
        let messageBuffer = '';
        let isMessageComplete = false;

        ollamaResponse.data.on('data', (chunk) => {
          const chunkStr = chunk.toString();
          messageBuffer += chunkStr;

          if (firstChunk) {
            // Inject model info into the first chunk
            if (chunkStr.includes('"model"')) {
              // Replace the model name with our enhanced version
              const enhancedChunk = chunkStr.replace(
                `"model":"${recommendedModel}"`,
                `"model":"${recommendedModel} (OllamaGeek enhanced)"`
              );
              res.write(enhancedChunk);
            } else {
              res.write(chunk);
            }
            firstChunk = false;
          } else {
            // Check if this chunk completes a message
            if (chunkStr.includes('"done":true')) {
              isMessageComplete = true;
            }

            // If message is complete, inject model note
            if (isMessageComplete && chunkStr.includes('"content"')) {
              const enhancedChunk = chunkStr.replace(
                /"content":"([^"]*)"/,
                `"content":"$1\\n\\n---\\nðŸ¤– **OllamaGeek AI Assistant**\\nðŸŽ¯ **Model Used:** ${recommendedModel}\\nâ° **Timestamp:** ${new Date().toLocaleString()}\\n---"`
              );
              res.write(enhancedChunk);
              isMessageComplete = false;
            } else {
              res.write(chunk);
            }
          }
        });

        ollamaResponse.data.on('end', () => {
          res.end();
        });

        // Update session after successful streaming response
        sessionManager.updateSession(sessionId, req.body.messages || []);
      } catch (ollamaError) {
        console.error('âŒ Ollama streaming error:', {
          status: ollamaError.response?.status,
          data: ollamaError.response?.data,
          message: ollamaError.message,
          request: ollamaRequest
        });
        throw ollamaError;
      }
    } else {
      // Handle non-streaming response
      try {
        const ollamaResponse = await axios.post(`${process.env.OLLAMA_BASE_URL || 'http://localhost:11434'}/api/chat`, cleanRequest, {
          headers: {
            'Content-Type': 'application/json'
          }
        });

                // Enhance the response with model information
        const enhancedResponse = {
          ...ollamaResponse.data,
          model: `${ollamaResponse.data.model} (OllamaGeek enhanced)`,
          _ollamaGeek: {
            originalModel: req.body.model,
            selectedModel: recommendedModel,
            taskType: analysis.taskType,
            complexity: analysis.complexity,
            reasoning: analysis.reasoning
          }
        };

        // Return the enhanced response
        res.json(enhancedResponse);

        // Update session after successful response
        sessionManager.updateSession(sessionId, req.body.messages || []);
      } catch (ollamaError) {
        console.error('âŒ Ollama non-streaming error:', {
          status: ollamaError.response?.status,
          data: ollamaError.response?.data,
          message: ollamaError.message,
          request: ollamaRequest
        });
        throw ollamaError;
      }
    }
  } catch (error) {
    next(error);
  }
});

app.post('/api/embeddings', async (req, res, next) => {
  try {
    const result = await orchestrator.handleEmbeddings(req.body);
    res.json(result);
  } catch (error) {
    next(error);
  }
});

app.get('/api/tags', async (req, res, next) => {
  try {
    const result = await orchestrator.handleTags();
    res.json(result);
  } catch (error) {
    next(error);
  }
});

app.post('/api/pull', async (req, res, next) => {
  try {
    const result = await orchestrator.handlePull(req.body);
    res.json(result);
  } catch (error) {
    next(error);
  }
});

app.post('/api/push', async (req, res, next) => {
  try {
    const result = await orchestrator.handlePush(req.body);
    res.json(result);
  } catch (error) {
    next(error);
  }
});

// Additional orchestration endpoints (invisible to standard Ollama clients)
app.post('/api/orchestrate', async (req, res, next) => {
  try {
    const result = await orchestrator.handleOrchestration(req.body);
    res.json(result);
  } catch (error) {
    next(error);
  }
});

// Tool discovery endpoint for Continue
app.get('/api/tools', async (req, res) => {
  try {
    console.log('ðŸ” /api/tools endpoint called - Continue discovering tools');

    const availableTools = [
      {
        name: "create_file",
        description: "Create new files with specified content",
        parameters: {
          path: "string - File path to create",
          content: "string - File content",
          language: "string - Programming language (optional)"
        }
      },
      {
        name: "create_directory",
        description: "Create new directories",
        parameters: {
          path: "string - Directory path to create"
        }
      },
      {
        name: "edit_file",
        description: "Modify existing files",
        parameters: {
          path: "string - File path to edit",
          content: "string - New file content"
        }
      },
      {
        name: "delete_file",
        description: "Remove files",
        parameters: {
          path: "string - File path to delete"
        }
      },
      {
        name: "run_terminal",
        description: "Execute terminal commands",
        parameters: {
          command: "string - Command to execute",
          cwd: "string - Working directory (optional)"
        }
      },
      {
        name: "git_operation",
        description: "Perform git operations",
        parameters: {
          operation: "string - Git command (init, add, commit, etc.)",
          path: "string - Repository path (optional)"
        }
      },
      {
        name: "search_files",
        description: "Search file content",
        parameters: {
          query: "string - Search query",
          path: "string - Directory to search (optional)"
        }
      }
    ];

    res.json({
      tools: availableTools,
      capabilities: {
        tool_planning: true,
        file_operations: true,
        terminal_commands: true,
        git_operations: true,
        code_analysis: true,
        project_generation: true
      },
      model: "OllamaGeek Orchestrator",
      version: "1.0.0",
      description: "Intelligent AI assistant with powerful tool planning capabilities"
    });
  } catch (error) {
    console.error('âŒ Error in /api/tools:', error.message);
    res.status(500).json({ error: 'Failed to get tools' });
  }
});



// Enhanced context-aware planning endpoint
app.post('/api/plan/enhanced', async (req, res, next) => {
  try {
    // Session management: Create or get session ID
    const userAgent = req.get('User-Agent') || 'unknown';
    const sessionId = sessionManager.getSessionId(req.body, userAgent);
    const sessionHistory = sessionManager.getSessionHistory(sessionId);

    console.log(`ðŸ†” Enhanced Planning Session: ${sessionId} | History: ${sessionHistory.length} messages`);

    // Use embedding-based classification for intelligent model selection
    const analysis = await embeddingClassifier.classifyRequest(req.body);
    const recommendedModel = analysis.recommendedModel;

    console.log(`ðŸ§  Enhanced Planning Model: "${req.body.model}" -> "${recommendedModel}"`);
    console.log(`ðŸ“Š Analysis: ${analysis.taskType} | ${analysis.complexity} | ${analysis.language}`);

    // Get context recommendations based on the request
    console.log(`ðŸ§  Getting context recommendations...`);
    const contextRequest = await enhancedContextManager.getContextRecommendations(req.body.messages?.[0]?.content || req.body.prompt || '');

    // Request context from PluginGeek (simulated for now)
    console.log(`ðŸ§  Requesting context from PluginGeek...`);
    const contextResponse = await enhancedContextManager.requestContext(contextRequest);

    // Analyze context for AI planning
    console.log(`ðŸ§  Analyzing context for AI planning...`);
    const planningContext = await enhancedContextManager.analyzeContextForPlanning(
      req.body.messages?.[0]?.content || req.body.prompt || '',
      contextResponse
    );

    // Get tool plan from Ollama's intelligence with enhanced context
    console.log(`ðŸ§  Generating enhanced tool plan...`);
    const toolPlan = await agenticExecutor.planTools(req.body, planningContext);

    if (toolPlan && toolPlan.tools.length > 0) {
      console.log(`ðŸŽ¯ Enhanced tool plan generated: ${toolPlan.tools.length} tools needed`);
      console.log(`ðŸ“‹ Plan description: ${toolPlan.description}`);

      // Update feature tracking if this is a feature-related request
      if (planningContext.feature.currentFeature) {
        enhancedContextManager.updateFeatureTracking(
          planningContext.feature.currentFeature,
          'planning',
          planningContext.relevantFiles.map(f => f.path)
        );
      }

      // Return enhanced plan with context
      res.json({
        success: true,
        plan: {
          description: toolPlan.description,
          tools: toolPlan.tools.map(tool => ({
            name: tool.tool,
            description: tool.description,
            parameters: tool.parameters || {},
            context: tool.context || ''
          })),
          context: {
            workspace: planningContext.workspace,
            feature: planningContext.feature,
            rules: planningContext.rules,
            summary: planningContext.contextSummary,
            constraints: planningContext.constraints,
            recommendations: planningContext.analysis.recommendations
          },
          model: recommendedModel,
          sessionId: sessionId,
          contextId: contextResponse.contextId
        }
      });
    } else {
      // No tools needed - return enhanced response plan
      res.json({
        success: true,
        plan: {
          description: "No tools required - direct response needed",
          tools: [],
          context: {
            workspace: planningContext.workspace,
            feature: planningContext.feature,
            rules: planningContext.rules,
            summary: planningContext.contextSummary
          },
          model: recommendedModel,
          sessionId: sessionId,
          contextId: contextResponse.contextId
        }
      });
    }
  } catch (error) {
    console.error('âŒ Error in enhanced planning:', error.message);
    next(error);
  }
});

// Original planning endpoint - returns tool execution plan without executing
app.post('/api/plan', async (req, res, next) => {
  try {
    // Session management: Create or get session ID
    const userAgent = req.get('User-Agent') || 'unknown';
    const sessionId = sessionManager.getSessionId(req.body, userAgent);
    const sessionHistory = sessionManager.getSessionHistory(sessionId);

    console.log(`ðŸ†” Planning Session: ${sessionId} | History: ${sessionHistory.length} messages`);

    // Use embedding-based classification for intelligent model selection
    const analysis = await embeddingClassifier.classifyRequest(req.body);
    const recommendedModel = analysis.recommendedModel;

    console.log(`ðŸ§  Planning Model: "${req.body.model}" -> "${recommendedModel}"`);
    console.log(`ðŸ“Š Analysis: ${analysis.taskType} | ${analysis.complexity} | ${analysis.language}`);

    // Get smart context for the request
    const context = await contextManager.getSmartContext(req.body, analysis.taskType, analysis.complexity);
    if (context.files.length > 0 || context.gitStatus || context.reasoning) {
      console.log(`ðŸ“ Planning Context: ${contextManager.formatContext(context)}`);
    }

    // Get tool plan from Ollama's intelligence
    console.log(`ðŸ§  Generating tool plan...`);
    const toolPlan = await agenticExecutor.planTools(req.body, context);

    if (toolPlan && toolPlan.tools.length > 0) {
      console.log(`ðŸŽ¯ Tool plan generated: ${toolPlan.tools.length} tools needed`);
      console.log(`ðŸ“‹ Plan description: ${toolPlan.description}`);

      // Return structured plan for VS Code extension to execute
      res.json({
        success: true,
        plan: {
          description: toolPlan.description,
          tools: toolPlan.tools.map(tool => ({
            name: tool.tool,
            description: tool.description,
            parameters: tool.parameters || {},
            context: tool.context || ''
          })),
          context: toolPlan.context,
          model: recommendedModel,
          sessionId: sessionId
        }
      });
    } else {
      // No tools needed - return simple response plan
      res.json({
        success: true,
        plan: {
          description: "No tools required - direct response needed",
          tools: [],
          context: context,
          model: recommendedModel,
          sessionId: sessionId
        }
      });
    }
  } catch (error) {
    console.error('âŒ Error in /api/plan:', error.message);
    next(error);
  }
});

// Unified chat endpoint - handles classification and planning internally
app.post('/api/chat/unified', async (req, res, next) => {
  try {
    const { prompt, context } = req.body;

    if (!prompt) {
      return res.status(400).json({ error: 'Prompt is required' });
    }

    console.log(`ðŸ’¬ Chat endpoint called with: "${prompt}"`);

    // Use intelligent intent recognition system
    console.log(`ðŸ§  Using intelligent intent recognition for: "${prompt}"`);

    try {
      // Recognize user intent using multiple approaches
      const intentResult = await intentRecognizer.recognizeIntent(prompt, context);
      console.log(`ðŸŽ¯ Intent Recognition Result:`, intentResult);

      // Map intent to specific approach and action type
      const mappedApproach = approachMapper.mapIntentToApproach(intentResult);
      console.log(`ðŸ—ºï¸ Mapped Approach:`, mappedApproach);

      // Validate approach based on context
      const validatedApproach = approachMapper.validateApproach(mappedApproach, context);
      console.log(`âœ… Validated Approach:`, validatedApproach);

      // Generate appropriate response based on approach
      const response = approachMapper.generateResponse(prompt, intentResult, validatedApproach);
      
      // If it's a simple chat, return immediately
      if (response.type === 'simple_chat') {
        return res.json(response);
      }

      // For execution tasks, continue with planning
      const actionType = validatedApproach.actionType;
      console.log(`ðŸŽ¬ Action Type Determined: ${actionType}`);

    // Handle different action types
    switch (actionType) {
      // Simple chat is now handled by the approach mapper above
      // case 'simple_chat':
        // All simple chat logic moved to approach mapper - this case is no longer used
        let directResponse = '';

        // Math questions
        if (/^(what is|what's|how much is|calculate|compute|solve).*[0-9+\-*/()\s.]+/i.test(prompt) ||
            /^[0-9+\-*/()\s.]+=?\s*$/i.test(prompt) ||
            /what is.*[0-9+\-*/()\s.]+/i.test(prompt) ||
            /calculate.*[0-9+\-*/()\s.]+/i.test(prompt) ||
            /compute.*[0-9+\-*/()\s.]+/i.test(prompt)) {
          try {
            let mathExpr = prompt.replace(/^(what is|what's|how much is|calculate|compute|solve)\s+/i, '').replace(/[?]?\s*$/i, '').trim();
            mathExpr = mathExpr
              .replace(/\bplus\b/gi, '+')
              .replace(/\bminus\b/gi, '-')
              .replace(/\btimes\b/gi, '*')
              .replace(/\bdivided by\b/gi, '/')
              .replace(/\band\b/gi, '+');

            if (/^[0-9+\-*/()\s*()\s.]+$/.test(mathExpr)) {
              const result = eval(mathExpr);
              directResponse = `${mathExpr} = ${result}`;
            } else {
              // Try to extract just the numbers and operators
              const numbers = prompt.match(/[0-9]+/g);
              const operators = prompt.match(/[\+\-\*\/]/g);
              if (numbers && numbers.length >= 2 && operators && operators.length >= 1) {
                const expr = numbers.join(operators[0]);
                const result = eval(expr);
                directResponse = `${expr} = ${result}`;
              }
            }
          } catch (error) {
            directResponse = "I couldn't calculate that math expression safely.";
          }
        }

        // Greetings
        if (/^(hello|hi|hey|greetings|good morning|good afternoon|good evening|how are you|how's it going|what's up|sup|hey there|good day)/i.test(prompt)) {
          const greetings = [
            "Hello! How can I help you today?",
            "Hi there! What would you like to work on?",
            "Hey! I'm ready to assist with your development tasks.",
            "Good day! What can I help you build or analyze today?",
            "Hi! I'm your AI development assistant. What's on your mind?"
          ];
          directResponse = greetings[Math.floor(Math.random() * greetings.length)];
        }

        // General questions
        if (/^(how tall|how big|how long|how wide|how heavy|how much does|how many|how old|what color|what time|what day|what year)/i.test(prompt)) {
          const responses = [
            "I'm an AI assistant, so I don't have physical characteristics like height or weight. I'm here to help you with coding, development, and technical tasks!",
            "That's an interesting question, but I'm a development-focused AI assistant. I can help you with programming, code analysis, and building applications instead.",
            "I'm a virtual assistant designed for development work, so I don't have physical attributes. How about we work on some code or development tasks instead?"
          ];
          directResponse = responses[Math.floor(Math.random() * responses.length)];
        }

        // File content updates (like "put it in yes.txt")
        if (prompt.includes('put') && prompt.includes('in') && /\.(txt|js|py|md|json|html|css)$/i.test(prompt)) {
          // This should be an execution task, not simple chat
          console.log(`ðŸ”§ File content update detected, redirecting to execution`);
          actionType = 'execution_simple';
          // Break out of simple_chat case to handle as execution
          break;
        }

        // If no direct response found, use a default response
        if (!directResponse) {
          directResponse = "I'm here to help! What would you like to work on?";
        }

        return res.json({
          type: 'simple_chat',
          message: directResponse,
          tools: [],
          requiresApproval: false,
          modelUsed: classificationResult ? `${classificationResult.recommendedModel} (AI classification)` : 'pattern-based (fallback)',
          actionType: actionType
        });

      case 'planning_task':
        // Generate simple plan response
        return res.json({
          type: 'planning_task',
          message: `I'll help you plan: ${prompt}. This is a planning task that would benefit from a detailed plan and .md file.`,
          tools: [],
          requiresApproval: false,
          modelUsed: classificationResult ? `${classificationResult.recommendedModel} (AI classification)` : 'pattern-based (fallback)',
          actionType: actionType,
          plan: `Planning task: ${prompt}`
        });

      case 'execution_simple':
      case 'execution_complex':
        // Use full planning for execution tasks
        console.log(`ðŸ”§ Execution task detected, using full planning...`);

        // Get context recommendations
        const contextRequest = await enhancedContextManager.getContextRecommendations(prompt);
        const contextResponse = await enhancedContextManager.requestContext(contextRequest);
        const planningContext = await enhancedContextManager.analyzeContextForPlanning(prompt, contextResponse);

        // Generate tool plan
        const toolPlan = await agenticExecutor.planTools({ prompt }, planningContext);

        return res.json({
          type: 'execution_task',
          message: toolPlan.description || `I'll help you with: ${prompt}`,
          tools: toolPlan.tools.map(tool => ({
            name: tool.tool,
            description: tool.description,
            parameters: tool.parameters || {},
            context: tool.context || ''
          })),
          requiresApproval: actionType === 'execution_complex',
          modelUsed: classificationResult ? `${classificationResult.recommendedModel} (AI classification)` : 'pattern-based (fallback)',
          actionType: actionType,
          context: {
            workspace: planningContext.workspace,
            feature: planningContext.feature,
            rules: planningContext.rules,
            summary: planningContext.contextSummary
          }
        });

      default:
        return res.json({
          type: 'execution_task',
          message: `I'll help you with: ${prompt}`,
          tools: [],
          requiresApproval: false,
          modelUsed: 'pattern-based',
          actionType: 'execution_simple'
        });
    }

  } catch (error) {
    console.error('âŒ Error in /api/chat:', error.message);
    next(error);
  }
});

// Error handling middleware
app.use(ErrorHandler.middleware);

// 404 handler for unmatched routes
app.use('*', (req, res) => {
  res.status(404).json({
    error: 'Not found',
    message: 'This endpoint is not supported by the Ollama API wrapper'
  });
});

// Start server
app.listen(PORT, () => {
  console.log(`ðŸš€ OllamaGeek API wrapper running on port ${PORT}`);
  console.log(`ðŸ“¡ Forwarding requests to: ${process.env.OLLAMA_BASE_URL || 'http://localhost:11434'}`);
  console.log(`ðŸ§  Orchestration enabled: ${process.env.ENABLE_AGENTIC_ORCHESTRATION === 'true' ? 'Yes' : 'No'}`);
  console.log(`ðŸ†” Session management enabled with ${sessionManager.maxHistoryLength} message history`);
});

// Clean up expired sessions every 5 minutes
setInterval(() => {
  sessionManager.cleanupExpiredSessions();
}, 5 * 60 * 1000);

// Graceful shutdown
process.on('SIGTERM', () => {
  console.log('ðŸ›‘ Received SIGTERM, shutting down gracefully...');
  process.exit(0);
});

process.on('SIGINT', () => {
  console.log('ðŸ›‘ Received SIGINT, shutting down gracefully...');
  process.exit(0);
});

module.exports = app;
